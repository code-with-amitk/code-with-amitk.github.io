<!DOCTYPE html>
<html>
  <head>
    <title>Rate Limiter</title>
    <link rel="stylesheet" href="/css/styles.css"/>
    <link rel="stylesheet" href="/css/prism.css"/>
  </head>

<body>
  <nav class="navbar">    <!--See .navbar in styles.css-->
    <ul>
      <li><a href="/">Home</a></li>
      <li><a href="#">Our team</a></li>
      <li><a href="#">Projects</a></li>
      <li><a href="/contact.html">Contact</a></li>
      <li>
        <form id="searchForm">
            <input type="search" id="searchInput" name="q" placeholder="Search site" />
            <input type="submit" value="Go!" />
        </form>
        </li>
    </ul>
  </nav>

  <aside class="sidebar">
    <a href="#what">What</a>
    <a href="#req">Requirements</a>
    <a href="#hld">HLD</a>
    <ul>
      <li><a href="#rla">Rate Limiting Algorithms</a></li>
      <li><a href="#implement_req1">Req1</a></li>
      <li><a href="#implement_req2">Req2</a></li>
    </ul>
    <a href="#issues">Issues</a>
    <ul>
      <li><a href="#racecondition">Race Condition</a></li>
      <li><a href="#synchronizationissue">Synchronization issue</a></li>
    </ul>
  </aside>

  <main>
    <article style="margin-left:200px;">
        <h2 id="what">What is Rate Limiter</h2>
        <dl>
          Restricts number of incoming <b>HTTP Requests/REST API calls</b> from client to server, which can overload the server.<br>
          Eg: Only 2 HTTP Posts/sec, 10 accounts creation allowed from same IP address, 300 tweets/3 hours.
        </dl>
        <dl>
        <b>AWS API gateway</b> is a fully managed service that supports rate limiting, SSL termination, 
        authentication, IP whitelisting, servicing static content, etc
        </dl>

        <dl><strong>Benefits of RL</strong></dl>
        <dd>
          Prevent resource starvation caused by Denial of Service (DoS) attack<br>
          Limiting excess requests means fewer servers(Cost reduction)<br>
        </dd>

        <h2>1. Requirements</h2>
        <h3>Functional</h3>
        <dd>CRUD(Create=POST, Read=GET, Update=PUT, Delete=DELETE)</dd>
        <dl id="req1">1. Limit excessive requets (Criteria: UserId, IP Address etc)</dl>
        <dl id="req2">2. Inform user when his request is dropped</dl>

        <h3>Non Functional</h3>
        <dd>
          S<sup>3</sup>:(Scalable,Secure,SOA), L<sup>3</sup>:(Latency, Load, Logging), 
          A<sup>3</sup>:(Accurate, Available, Authenticated), C<sup>2</sup>:(Cache),
          R<sup>2</sup>:(Reliable, Redundant) F<sup>2</sup>:(fast, Fault Tolerant)
        </dd>
        <dl id="nonfuncreq1">1. Latency should be Low. ie dropped user should be quickly informed</dl>
        <dl id="nonfuncreq2">2. Low Memory usage</dl>
        <dl id="nonfuncreq3">3. Highly Reliable. (ie fault Tolerant)</dl>

        <h2 id="hld">2. HLD</h2>
        <dl>
        Rate limiting can be implemented using different algorithms, and each of them has distinct pros and cons.
        </dl>

        <h3 id="rla">Rate Limiting Algorithms</h3>
        <table>
          <tr>
            <th>Name</th>
            <th>Used By</th>
            <th>Description</th>
          </tr>
          <tr>
            <td>Token Bucket</td>
            <td>Amazon, Stripe</td>
            <td>
              - <a href="https://github.com/code-with-amitk/pvt-research/blob/master/Projects/Clear2Pay/README.adoc#2-implement-token-bucket-algorithms">Description</a><br>
              - Advatanges: Easy to implement, Memory Efficient, Allows a burst of traffic for short periods, ie requests can go until tokens are present then request stop for some time<br>
              - Disdvatanges: Two parameters in the algorithm are bucket size and token refill rate, which might be challenging to tune.
            </td>
          </tr>
          <tr>
            <td>Leaky Bucket</td>
            <td>Shopify</td>
            <td>
              - <a href="https://github.com/code-with-amitk/pvt-research/blob/master/Projects/Clear2Pay/README.adoc#2-leaky-bucket-queuefifo">Description</a><br>
              - Advatanges: Memory efficient given the limited queue size, Requests are processed at a fixed rate(smoothens the bursty traffic)<br>
              - Disdvatanges:  There are two parameters in the algorithm. It might not be easy to tune them properly
            </td>
          </tr>
        </table>

        <h4 id="implement_req1">
          <a href="#req1">Req1. Limit excessive requets (Criteria: UserId, IP Address etc)</a>
        </h4>
        <dl>
          Rate limiting is done using above Rate limiting algorithms<br>
          Ratelimiting HW will store the rules on the disk. Workers frequently pull rules from the disk and store them in the cache<br>
        </dl>

        <h5 id="counters">Counters</h5>
        <dt>
          To keep track of how many requests are sent from the same user, IP address, etc. If the counter is
          larger than the limit, the request is disallowed<br>

          <br>
          <b><u>For 1 million users:</u></b> <br>
          &ensp; 5 million counters. if each user is rate limited on 5 parameters<br>
          <pre><code class="language-css">
Userid      TCP SYN Rcvd/sec(Connect req)   HTTP GET Rcvd
  1                10                           5
  5                1000                         5000      //Pumping huge traffic
          </code></pre>
          
          <br>
          <b><u>Where to store counters?</u></b> REDIS<br>
          Option-1: File on Hard Disk (slow)<br>
          Option-2: inmemory store = Redis
        </dt>

        <h5 id="rules">Rate Limiting Rules</h5>
        <dl>
          Requests allowed in particular category. <br>
          Rules are stored on the disk. Workers frequently pull rules from the disk and store them in the cache
        </dl>
        <pre><code class="language-css">
Examples:

domain: messaging
descriptors:
  - key: message_type
    Value: marketing                //Only 5 marketing messages/day.
    rate_limit:
      unit: day
      requests_per_unit: 5

domain: auth
descriptors:
  - key: auth_type
    Value: login                 // Only 5 login requests/minute
    rate_limit:
      unit: minute
      requests_per_unit: 5      
        </code></pre>

        <h5>Architecture & Flow</h5>
        <table>
          <tr>
            <td>
              <img src="/images/rate_limiter/architecture.PNG" alt="trie" style="width:500px;height:300px;">
            </td>
            <td>
              <b>Flow:</b><br>
              1. Client sends a request to the server, the request is sent to the rate limiter middleware first.<br>
              2. Rate limiter middleware loads <a href="#rules">rules from the cache</a>. It fetches 
              <a href="#counters">counters</a> and last request timestamp from Redis cache.<br>
              3. Based on the response, the rate limiter decides <br>
              &ensp; Forward to API Server, if not rate limited<br>
              &ensp; Returns 429 too many requests, if the request is rate limited    
            </td>
          </tr>
        </table>
        

        <h4 id="implement_req2">
          <a href="#req2">Req2. Inform user when his request is dropped</a>
        </h4>
        <dl>
          User is informed using <a href="/Networking/OSI-Layers/Layer-7/HTTP/#methods">HTTP Response headers</a><br>
          - X-Ratelimit-Remaining: The remaining number of allowed requests within the window.<br>
          - X-Ratelimit-Limit: It indicates how many calls the client can make per time window.<br>
          - X-Ratelimit-Retry-After: The number of seconds to wait until you can make a request again without being throttled
        </dl>

        <h2 id="issues">Issues</h2>
        <h3 id="racecondition">1. Race condition</h3>
        <dl><strong>Race Condition in reading counter from Redis</strong></dl>
        <dl>
          • Read the counter value from Redis.<br>
          • Check if ( counter + 1 ) exceeds the threshold.<br>
          • If not, increment the counter value by 1 in Redis.<br>
          - Assume the counter value in Redis is 3. If two requests concurrently read the counter value
          before either of them writes the value back, each will increment the counter by one and write
          it back without checking the other thread. <br>
          - Both requests (threads) believe they have the
            correct counter value 4. However, the correct counter value should be 5.
        </dl>
        
        <img src="/images/rate_limiter/redis_race_condition.PNG" alt="trie" style="width:400px;height:200px;">

        <dl><strong>How to avoid Race Condition?</strong></dl>
        <dl>
          Lua script and sorted sets data structure in Redis
        </dl>

        <h3 id="synchronizationissue">2. Synchronization issue</h3>
        <dl>

        </dl>

    </article>
  </main>

  <script src="/scripts/prism.js"></script>
</body>
</html>
